import re
import aiohttp
import asyncio
import json
import pandas as pd
import numpy as np
import time
import os
import sqlite3
from datetime import datetime
from json import JSONDecodeError
import streamlit as st
import altair as alt
import requests

API_KEY = os.getenv("DEEPSEEK_API_KEY", "sk-e4eaafa61ff349cbb93e554b64c22dcb")
BASE_URL = "https://api.deepseek.com/v1/chat/completions"

VALID_INDUSTRIES = ["ç¾å¦†", "æ•™è‚²", "3Cæ•°ç ", "æ¯å©´", "ç¾é£Ÿ"]

INDUSTRY_PROMPTS = {
    "ç¾å¦†": "å¼ºè°ƒæˆåˆ†åˆ†æå’Œä½¿ç”¨åœºæ™¯",
    "æ•™è‚²": "é›†ä¸­å­¦ä¹ æ•ˆæœè§†è§‰åŒ–",
    "3Cæ•°ç ": "å…³æ³¨å‚æ•°å¯¹æ¯”å’Œå®æµ‹ä½“éªŒ",
    "æ¯å©´": "æ³¨é‡å®‰å…¨æ€§å’Œç”¨æˆ·ä½“éªŒ",
    "ç¾é£Ÿ": "çªå‡ºå£æ„Ÿå’Œåœ°åŸŸæ–‡åŒ–"
}

PLATFORM_RULES = {
    "æŠ–éŸ³": {"æ—¶é•¿": "15-60ç§’", "æ ‡é¢˜è§„åˆ™": "å¸¦äº‰è®®ç‚¹"},
    "å°çº¢ä¹¦": {"ç¬”è®°ç»“æ„": "å°é¢+æ ‡è®°ç‚¹", "æ ‡é¢˜è§„åˆ™": "ä½“éªŒåˆ†äº«"}
}

RISK_REPLACEMENTS = {
    "æœ€": "å¯èƒ½",
    "ç¬¬ä¸€": "å‰åˆ—",
    "ç»å¯¹": "å»ºè®®"
}

async def compare_competitors_async(competitor_list, platform):
    data = []
    async with aiohttp.ClientSession() as session:
        tasks = [get_account_data(session, platform, comp) for comp in competitor_list]
        results = await asyncio.gather(*tasks)
        for result in results:
            data.append({
                "è´¦å·åç§°": result.get("æ˜µç§°", "æœªçŸ¥"),
                "å¹³å°": platform,
                "ç²‰ä¸é‡çº§": result.get("ç²‰ä¸æ•°", 0),
                "å†…å®¹æ•°é‡": result.get("ä½œå“æ•°", result.get("ç¬”è®°æ•°", result.get("è§†é¢‘æ•°", 0)))
            })
    df = pd.DataFrame(data)
    return df

def call_deepseek_api(input_data, task, industry=""):
    headers = {"Authorization": f"Bearer {API_KEY}", "Content-Type": "application/json"}
    payload = json.dumps({
        "model": "deepseek-reasoner",
        "messages": [
            {"role": "system", "content": f"ä½ æ˜¯ä¸€å{industry}é¢†åŸŸè´¦å·è§„åˆ’å¸ˆï¼Œéœ€ç‰¹åˆ«å…³æ³¨{INDUSTRY_PROMPTS.get(industry, 'é€šç”¨ç­–ç•¥')}ã€‚"},
            {"role": "user", "content": f"{task}: {input_data}"}
        ],
        "stream": False
    })
    response = requests.post(BASE_URL, headers=headers, data=payload)
    try:
        return response.json()
    except JSONDecodeError:
        return {}

def parse_analysis_result(raw_result):
    return {
        "äººè®¾å®šä½": raw_result.get("persona", "æœªæ‰¾åˆ°"),
        "å·®å¼‚ç‚¹åˆ†æ": raw_result.get("differentiation", []),
        "é£é™©æç¤º": raw_result.get("risk", "æ— ")
    }

def parse_topics(raw_text):
    return re.findall(r'\d+\.\s+(.*)', raw_text)

def generate_calendar(topics):
    dates = pd.date_range(start=datetime.today(), periods=len(topics))
    return pd.DataFrame({
        "æ—¥æœŸ": dates,
        "é€‰é¢˜": topics,
        "å¹³å°": ["æŠ–éŸ³" if i % 2 == 0 else "å°çº¢ä¹¦" for i in range(len(topics))]
    })

def save_analysis_history(analysis_data):
    conn = sqlite3.connect('analytics.db')
    c = conn.cursor()
    c.execute('''CREATE TABLE IF NOT EXISTS histories (
                   id INTEGER PRIMARY KEY,
                   account_name TEXT,
                   industry TEXT,
                   created_at TIMESTAMP)''')
    c.execute("INSERT INTO histories (account_name, industry, created_at) VALUES (?, ?, ?)", 
              (analysis_data['account_name'], analysis_data['industry'], datetime.now()))
    conn.commit()
    conn.close()

def auto_correct(text):
    for kw, rep in RISK_REPLACEMENTS.items():
        text = text.replace(kw, rep)
    return text

def generate_platform_spec(topics, platform):
    return [f"{topic} [{PLATFORM_RULES[platform]['æ ‡é¢˜è§„åˆ™']}]" for topic in topics]

def streamlit_app():
    st.title("ğŸ“¢ DeepSeek è´¦å·äººè®¾è§„åˆ’ç³»ç»Ÿ")
    st.markdown("## è´¦å·åŸºç¡€ä¿¡æ¯")
    account_name = st.text_input("ğŸ“Œ è´¦å·åç§°")
    industry = st.selectbox("ğŸ¢ æ‰€åœ¨è¡Œä¸š", VALID_INDUSTRIES)

    st.markdown("## æ ¸å¿ƒä¼˜åŠ¿")
    core_advantages = st.text_area("ğŸ’¡ æ ¸å¿ƒä¼˜åŠ¿ (æ¢è¡Œåˆ†éš”)").split("\n")

    st.markdown("## ç›®æ ‡äººç¾¤ç”»åƒ")
    target_audience = st.text_area("ğŸ‘¥ å¹´é¾„/åœ°åŒº/å…´è¶£")

    st.markdown("## ç«å“è´¦å·åˆ†æ")
    competitor_accounts = st.text_area("ç«å“è´¦å· (æ¢è¡Œåˆ†éš”)").split("\n")
    competitor_platform = st.selectbox("ğŸ“² å¹³å°", ["æŠ–éŸ³", "å°çº¢ä¹¦", "è§†é¢‘å·"])

    st.markdown("## è¿è¥ç›®æ ‡")
    operation_goal = st.selectbox("ğŸ¯ ç›®æ ‡", ["ç²‰ä¸å¢é•¿", "å“ç‰Œæ›å…‰", "äº§å“é”€å”®", "20ä¸ªçˆ†æ¬¾é€‰é¢˜"])

    if st.button("ğŸ” ç”Ÿæˆè´¦å·åˆ†ææŠ¥å‘Š"):
        with st.spinner("æ­£åœ¨åˆ†æè´¦å·äººè®¾ï¼Œè¯·ç¨å..."):
            input_data = {
                "account_name": account_name,
                "industry": industry,
                "core_advantages": core_advantages,
                "target_audience": target_audience,
                "competitor_accounts": competitor_accounts,
                "operation_goal": operation_goal
            }

            analysis_response = call_deepseek_api(json.dumps(input_data, ensure_ascii=False), "è´¦å·äººè®¾åˆ†æ", industry)
            raw_result = analysis_response.get("choices", [{}])[0].get("message", {}).get("content", {})
            parsed_result = parse_analysis_result(raw_result)

            st.success("âœ… åˆ†æå®Œæˆ")
            save_analysis_history(input_data)

            st.subheader("ğŸ“‘ è´¦å·äººè®¾åˆ†æç»“æœ")
            st.markdown(f"**äººè®¾å®šä½å»ºè®®**: {parsed_result['äººè®¾å®šä½']}")
            st.markdown("**å·®å¼‚åŒ–åˆ†æ**:")
            for diff in parsed_result['å·®å¼‚ç‚¹åˆ†æ']:
                st.markdown(f"- {diff}")
            st.markdown("**âš ï¸ é£é™©æç¤º**:")
            st.markdown(auto_correct(parsed_result['é£é™©æç¤º']))

            if operation_goal == "20ä¸ªçˆ†æ¬¾é€‰é¢˜":
                hot_topics_result = call_deepseek_api(parsed_result["äººè®¾å®šä½"], "ç”Ÿæˆ20ä¸ªçˆ†æ¬¾é€‰é¢˜", industry)
                raw_text = hot_topics_result.get("choices", [{}])[0].get("message", {}).get("content", "æœªç”Ÿæˆé€‰é¢˜")
                topics = parse_topics(raw_text)
                st.subheader("ğŸ”¥ ç”Ÿæˆçš„çˆ†æ¬¾é€‰é¢˜")
                for topic in topics:
                    st.markdown(f"- {topic}")

                calendar_df = generate_calendar(topics)
                st.dataframe(calendar_df)

                st.download_button("ğŸ“… ä¸‹è½½ CSV æ ¼å¼", calendar_df.to_csv(index=False), "content_calendar.csv")
                st.download_button("ğŸ“‘ ä¸‹è½½ Excel æ ¼å¼", calendar_df.to_excel(index=False), "content_calendar.xlsx")
                st.download_button("ğŸ“ ä¸‹è½½ JSON æ ¼å¼", calendar_df.to_json(orient='records', force_ascii=False), "content_calendar.json")

            competitor_df = asyncio.run(compare_competitors_async(competitor_accounts, competitor_platform))
            st.subheader("ç«å“è´¦å·å¯¹æ¯”åˆ†æ")
            st.dataframe(competitor_df)

            chart = alt.Chart(competitor_df).mark_bar().encode(
                x='è´¦å·åç§°',
                y='ç²‰ä¸é‡çº§',
                color='å¹³å°'
            )
            st.altair_chart(chart, use_container_width=True)

    st.markdown("---")
    st.markdown("ğŸ“¢ å…¨å¹³å° @æ—ºä»”AIGC")
    st.markdown("å…³æ³¨æˆ‘ï¼Œå’Œæˆ‘ä¸€èµ· æ‹†è§£æµé‡å¯†ç ï¼Œæ¢ç´¢ AIåˆ›ä½œæ–°ç©æ³•ï¼Œè®©ä½ çš„è´¦å·ç²¾å‡†å®šä½ï¼Œå†…å®¹ä¸å†è¿·è·¯ï¼ğŸš€")

if __name__ == "__main__":
    streamlit_app()
