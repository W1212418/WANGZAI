import re
import requests
import json
import pandas as pd
import streamlit as st
import numpy as np
import time
import os
import sqlite3
from datetime import datetime
from json import JSONDecodeError

# æš‚æ—¶ä¿ç•™ç¡¬ç¼–ç API KEYï¼ˆå®‰å…¨å‡çº§åæ”¹ä¸º st.secretsï¼‰
API_KEY = os.getenv("DEEPSEEK_API_KEY", "sk-e4eaafa61ff349cbb93e554b64c22dcb")

# æ›´æ–° API ç«¯ç‚¹
BASE_URL = "https://api.deepseek.com/v1/chat/completions"

VALID_INDUSTRIES = ["ç¾å¦†", "æ•™è‚²", "3Cæ•°ç ", "æ¯å©´", "ç¾é£Ÿ"]

INDUSTRY_PROMPTS = {
    "ç¾å¦†": "å¼ºè°ƒæˆåˆ†åˆ†æå’Œä½¿ç”¨åœºæ™¯",
    "æ•™è‚²": "é›†ä¸­å­¦ä¹ æ•ˆæœè§†è§‰åŒ–",
    "3Cæ•°ç ": "å…³æ³¨å‚æ•°å¯¹æ¯”å’Œå®æµ‹ä½“éªŒ",
    "æ¯å©´": "æ³¨é‡å®‰å…¨æ€§å’Œç”¨æˆ·ä½“éªŒ",
    "ç¾é£Ÿ": "çªå‡ºå£æ„Ÿå’Œåœ°åŸŸæ–‡åŒ–"
}

PLATFORM_RULES = {
    "æŠ–éŸ³": {"æ—¶é•¿": "15-60ç§’", "æ ‡é¢˜è§„åˆ™": "å¸¦äº‰è®®ç‚¹"},
    "å°çº¢ä¹¦": {"ç¬”è®°ç»“æ„": "å°é¢+æ ‡è®°ç‚¹", "æ ‡é¢˜è§„åˆ™": "ä½“éªŒåˆ†äº«"}
}

RISK_REPLACEMENTS = {
    "æœ€": "å¯èƒ½",
    "ç¬¬ä¸€": "å‰åˆ—",
    "ç»å¯¹": "å»ºè®®"
}

# æŠ–éŸ³è´¦å·ä¿¡æ¯é‡‡é›†ï¼ˆç¤ºä¾‹ä»£ç ï¼Œéœ€è°ƒæ•´ä¸ºçœŸå®APIæˆ–çˆ¬è™«ï¼‰
def fetch_douyin_account_info(user_id):
    headers = {
        "User-Agent": "Mozilla/5.0 (iPhone; CPU iPhone OS 12_3 like Mac OS X) AppleWebKit/605.1.15",
        "Cookie": "tt_webid=ä½ çš„tt_webid",
    }
    api_url = f"https://www.iesdouyin.com/web/api/v2/user/info/?sec_uid={user_id}"
    try:
        response = requests.get(api_url, headers=headers)
        result = response.json()
        if result.get("user_info"):
            user_data = result["user_info"]
            return {
                "æ˜µç§°": user_data.get("nickname"),
                "ç²‰ä¸æ•°": user_data.get("follower_count"),
                "ä½œå“æ•°": user_data.get("aweme_count")
            }
        else:
            return {"error": "ç”¨æˆ·ä¿¡æ¯æœªè·å–"}
    except Exception as e:
        return {"error": str(e)}

# å°çº¢ä¹¦è´¦å·ä¿¡æ¯é‡‡é›†ï¼ˆç¤ºä¾‹ä»£ç ï¼‰
def fetch_xiaohongshu_account_info(user_id):
    headers = {
        "User-Agent": "XHS/7.36.0 (iPhone; iOS 14.6; Scale/3.00)",
        "Cookie": "abtest_env=product;",
    }
    api_url = f"https://www.xiaohongshu.com/api/sns/v1/user/{user_id}"
    try:
        response = requests.get(api_url, headers=headers)
        result = response.json()
        if result.get("data"):
            user_data = result["data"]
            return {
                "æ˜µç§°": user_data.get("nickname"),
                "ç²‰ä¸æ•°": user_data.get("follower_count"),
                "ç¬”è®°æ•°": user_data.get("note_count")
            }
        else:
            return {"error": "ç”¨æˆ·ä¿¡æ¯æœªè·å–"}
    except Exception as e:
        return {"error": str(e)}

# è§†é¢‘å·æ¨¡æ‹Ÿæ•°æ®ï¼ˆæš‚æœªå®ç°çœŸå®æ¥å£ï¼‰
def fetch_wechat_channels_account_info(account_name):
    return {
        "æ˜µç§°": account_name,
        "ç²‰ä¸æ•°": np.random.randint(1000, 500000),
        "è§†é¢‘æ•°": np.random.randint(10, 300)
    }

# ç»Ÿä¸€è°ƒç”¨

def get_account_data(platform, account_id_or_name):
    if platform == "æŠ–éŸ³":
        return fetch_douyin_account_info(account_id_or_name)
    elif platform == "å°çº¢ä¹¦":
        return fetch_xiaohongshu_account_info(account_id_or_name)
    elif platform == "è§†é¢‘å·":
        return fetch_wechat_channels_account_info(account_id_or_name)
    else:
        return {"error": "æš‚ä¸æ”¯æŒçš„å¹³å°"}

def validate_industry(input_industry):
    if input_industry not in VALID_INDUSTRIES:
        raise ValueError(f"æš‚ä¸æ”¯æŒè¯¥è¡Œä¸šåˆ†ç±»ï¼Œè¯·é€‰æ‹©ï¼š{', '.join(VALID_INDUSTRIES)}")

def call_deepseek_api(text, task, industry=""):
    headers = {"Authorization": f"Bearer {API_KEY}", "Content-Type": "application/json"}
    payload = json.dumps({
        "model": "deepseek-reasoner",
        "response_format": {"type": "json_object"},
        "messages": [
            {"role": "system", "content": f"ä½ æ˜¯ä¸€å{industry}é¢†åŸŸè´¦å·è§„åˆ’å¸ˆï¼Œéœ€ç‰¹åˆ«å…³æ³¨{INDUSTRY_PROMPTS.get(industry, 'é€šç”¨ç­–ç•¥')}ã€‚"},
            {"role": "user", "content": f"{task}: {text}"}
        ],
        "stream": False
    })
    response = requests.post(BASE_URL, headers=headers, data=payload)
    try:
        return response.json()
    except JSONDecodeError:
        st.error("APIè¿”å›æ ¼å¼å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥æç¤ºè¯é…ç½®")
        return {}

def parse_analysis_result(raw_result):
    return {
        "äººè®¾å®šä½": raw_result.get("persona", "æœªæ‰¾åˆ°"),
        "å·®å¼‚ç‚¹åˆ†æ": raw_result.get("differentiation", []),
        "é£é™©æç¤º": raw_result.get("risk", "æ— ")
    }

def parse_topics(hot_topics_raw_text):
    return re.findall(r'\d+\.\s+(.*)', hot_topics_raw_text)

def compare_competitors(competitor_list, platform):
    data = []
    for comp in competitor_list:
        info = get_account_data(platform, comp)
        data.append({
            "è´¦å·åç§°": info.get("æ˜µç§°", comp),
            "å¹³å°": platform,
            "ç²‰ä¸é‡çº§": info.get("ç²‰ä¸æ•°", 0),
            "å†…å®¹æ•°é‡": info.get("ä½œå“æ•°", info.get("ç¬”è®°æ•°", info.get("è§†é¢‘æ•°", 0)))
        })
    df = pd.DataFrame(data)
    st.dataframe(df)
    st.bar_chart(df.set_index("è´¦å·åç§°")["ç²‰ä¸é‡çº§"])

def generate_calendar(topics):
    dates = pd.date_range(start=datetime.today(), periods=len(topics))
    return pd.DataFrame({
        "æ—¥æœŸ": dates,
        "é€‰é¢˜": topics,
        "å¹³å°": ["æŠ–éŸ³" if i % 2 == 0 else "å°çº¢ä¹¦" for i in range(len(topics))]
    })

def save_analysis_history(analysis_data):
    conn = sqlite3.connect('analytics.db')
    c = conn.cursor()
    c.execute('''CREATE TABLE IF NOT EXISTS histories (
                   id INTEGER PRIMARY KEY,
                   account_name TEXT,
                   industry TEXT,
                   created_at TIMESTAMP)''')
    c.execute("INSERT INTO histories (account_name, industry, created_at) VALUES (?, ?, ?)", 
              (analysis_data['account_name'], analysis_data['industry'], datetime.now()))
    conn.commit()
    conn.close()

def auto_correct(text):
    for kw, rep in RISK_REPLACEMENTS.items():
        text = text.replace(kw, rep)
    return text

def generate_platform_spec(topics, platform):
    return [f"{topic} [{PLATFORM_RULES[platform]['æ ‡é¢˜è§„åˆ™']}]" for topic in topics]

def main():
    st.title("ğŸ“¢ DeepSeek è´¦å·äººè®¾è§„åˆ’ç³»ç»Ÿ")
    
    if "hot_topics" not in st.session_state:
        st.session_state["hot_topics"] = None
    if "analysis_result" not in st.session_state:
        st.session_state["analysis_result"] = None
    
    with st.form("user_input_form"):
        account_name = st.text_input("ğŸ“Œ è´¦å·åç§°")
        industry = st.selectbox("ğŸ¢ æ‰€åœ¨è¡Œä¸š", VALID_INDUSTRIES)
        core_advantages = st.text_area("ğŸ’¡ æ ¸å¿ƒä¼˜åŠ¿ (æ¢è¡Œåˆ†éš”)").split("\n")
        target_audience = st.text_area("ğŸ¯ ç›®æ ‡äººç¾¤ (è¯·æè¿°å¹´é¾„ã€åœ°åŒºã€å…´è¶£ç‚¹)")
        competitor_accounts = st.text_area("ğŸ“Š ç«å“è´¦å· (æ¢è¡Œåˆ†éš”)").split("\n")
        competitor_platform = st.selectbox("ğŸ“² ç«å“å¹³å°", ["æŠ–éŸ³", "å°çº¢ä¹¦", "è§†é¢‘å·"])
        operation_goal = st.selectbox("ğŸš€ è¿è¥ç›®æ ‡", ["ç²‰ä¸å¢é•¿", "å“ç‰Œæ›å…‰", "äº§å“é”€å”®", "20ä¸ªçˆ†æ¬¾é€‰é¢˜"])
        submit_button = st.form_submit_button("ğŸ” ç”Ÿæˆäººè®¾åˆ†ææŠ¥å‘Š")

    if submit_button:
        try:
            validate_industry(industry)
        except ValueError as ve:
            st.error(str(ve))
            return
        
        if len(core_advantages) > 5:
            st.warning("æ ¸å¿ƒä¼˜åŠ¿å»ºè®®ä¸è¶…è¿‡5ä¸ªå…³é”®ç‚¹")
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for i in range(1, 101, 5):
            status_text.write(f"â³ æ­£åœ¨åˆ†æè´¦å·äººè®¾ï¼Œè¯·ç¨å {i}%")
            progress_bar.progress(i / 100)
            time.sleep(0.1)
        
        input_data = {
            "account_name": account_name,
            "industry": industry,
            "core_advantages": core_advantages,
            "target_audience": target_audience,
            "competitor_accounts": competitor_accounts,
            "operation_goal": operation_goal
        }
        
        analysis_response = call_deepseek_api(json.dumps(input_data, ensure_ascii=False), "è´¦å·äººè®¾åˆ†æ", industry)
        raw_result = analysis_response.get("choices", [{}])[0].get("message", {}).get("content", {})
        st.session_state["analysis_result"] = parse_analysis_result(raw_result)
        
        status_text.write("âœ… è´¦å·äººè®¾åˆ†æå®Œæˆ")
        progress_bar.progress(1.0)
        
        save_analysis_history(input_data)

    if st.session_state["analysis_result"]:
        parsed_result = st.session_state["analysis_result"]
        
        st.markdown("---")
        st.subheader("ğŸ“Š è´¦å·äººè®¾åˆ†ææŠ¥å‘Š")
        
        with st.expander("ğŸ§  äººè®¾å®šä½å»ºè®®"):
            st.write(parsed_result["äººè®¾å®šä½"])
        
        with st.expander("ğŸ“Œ å·®å¼‚åŒ–åˆ†æ"):
            for diff in parsed_result["å·®å¼‚ç‚¹åˆ†æ"]:
                st.write(f"- {diff}")
        
        with st.expander("âš ï¸ é£é™©æç¤º"):
            st.warning(auto_correct(parsed_result["é£é™©æç¤º"]))
        
        if st.button("ğŸ”¥ ç”Ÿæˆè¡Œä¸šçˆ†æ¬¾é€‰é¢˜"):
            with st.spinner("æ­£åœ¨ç”Ÿæˆçˆ†æ¬¾é€‰é¢˜ï¼Œè¯·ç¨å€™..."):
                hot_topics_result = call_deepseek_api(parsed_result["äººè®¾å®šä½"], "ç”Ÿæˆ20ä¸ªçˆ†æ¬¾é€‰é¢˜", industry)
                raw_text = hot_topics_result.get("choices", [{}])[0].get("message", {}).get("content", "æœªç”Ÿæˆé€‰é¢˜")
                st.session_state["hot_topics"] = raw_text
                st.success("âœ… çˆ†æ¬¾é€‰é¢˜ç”Ÿæˆå®Œæˆ")
                st.write(st.session_state["hot_topics"])
        
        if st.session_state["hot_topics"]:
            if st.button("ğŸ”„ æ¢ä¸€æ‰¹é€‰é¢˜"):
                with st.spinner("æ­£åœ¨é‡æ–°ç”Ÿæˆæ–°çš„çˆ†æ¬¾é€‰é¢˜ï¼Œè¯·ç¨å€™..."):
                    hot_topics_result = call_deepseek_api(parsed_result["äººè®¾å®šä½"], "ç”Ÿæˆ20ä¸ªçˆ†æ¬¾é€‰é¢˜", industry)
                    raw_text = hot_topics_result.get("choices", [{}])[0].get("message", {}).get("content", "æœªç”Ÿæˆé€‰é¢˜")
                    st.session_state["hot_topics"] = raw_text
                    st.success("âœ… æ–°çš„çˆ†æ¬¾é€‰é¢˜ç”Ÿæˆå®Œæˆ")
                    st.write(st.session_state["hot_topics"])
            
            topics = parse_topics(st.session_state["hot_topics"])
            platform_topics = generate_platform_spec(topics, "æŠ–éŸ³")
            calendar_df = generate_calendar(platform_topics)
            st.dataframe(calendar_df)
            st.download_button("ğŸ“… ä¸‹è½½å†…å®¹æ’æœŸè¡¨", calendar_df.to_csv(index=False), "content_calendar.csv")
        
        compare_competitors(competitor_accounts, competitor_platform)
        
        st.markdown("---")
        st.markdown("ğŸ“¢ å…¨å¹³å° @æ—ºä»”AIGC ğŸ“¢")
        st.markdown("å…³æ³¨æˆ‘ï¼Œå’Œæˆ‘ä¸€èµ· æ‹†è§£æµé‡å¯†ç ï¼Œæ¢ç´¢ AIåˆ›ä½œæ–°ç©æ³•ï¼Œè®©ä½ çš„ è´¦å·ç²¾å‡†å®šä½ï¼Œå†…å®¹ä¸å†è¿·è·¯ï¼ğŸš€")

if __name__ == "__main__":
    main()
